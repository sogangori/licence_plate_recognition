{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import ast\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" #CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-5405bb3c52bd>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5405bb3c52bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_gpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/test_util.py\u001b[0m in \u001b[0;36mis_gpu_available\u001b[0;34m(cuda_only, min_cuda_compute_capability)\u001b[0m\n\u001b[1;32m   1561\u001b[0m   \"\"\"\n\u001b[1;32m   1562\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlocal_device\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlocal_device\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GPU\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0mgpu_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_capability_from_device_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/client/device_lib.py\u001b[0m in \u001b[0;36mlist_local_devices\u001b[0;34m(session_config)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mserialized_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   return [\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pywrap_device_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   ]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "tf.__version__, tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence = 9\n",
    "blank_num = -1\n",
    "characters_0 = '0123456789'\n",
    "characters_alphabet = 'ABCDEFGHIJKLMNPQRSTUVWXYZ-'\n",
    "characters_1 = '가나다라마바사아자하거너더러머버서어저허고노도로모보소오조호구누두루무부수우주'\n",
    "characters_1d = 'GNDLMBSOJHgndlmbsojhgNDLMBSOJHGNDLMBSUJ'\n",
    "characters_2 = '대배해제기교표외인천국합육공영준협정울경강원충북운남전산광'\n",
    "characters_2d = 'DBHJGGPYICGHUGYJHJUGKWCBUNJSG'\n",
    "characters_3 = '_       abcd  '\n",
    "plate_characters = characters_0 + characters_alphabet + characters_1 + characters_2 + characters_3\n",
    "num_classes = len(plate_characters)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_image_shape = (16*6, 16*6*3)\n",
    "EOS = num_classes - 1\n",
    "SOS = EOS - 1\n",
    "head_n = 8\n",
    "l1 = 1e-8\n",
    "activation = 'relu'#'selu' is not converted to tflite\n",
    "kernel_init = tf.initializers.he_normal()\n",
    "path_weight = \"model/LPR\"\n",
    "max_data_m = 10\n",
    "SOS, EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_synthetic = '/home/mvlab/Downloads/plate_generator/gen/'\n",
    "path_label = path_synthetic + 'label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isdir(path_synthetic), os.path.isfile(path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_label, sep=' ')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_synthetic(max_m=10000):\n",
    "    df = pd.read_csv(path_label, sep=' ')\n",
    "    df = df[:max_m]\n",
    "    m = len(df)\n",
    "    x0 = df['x0']\n",
    "    x1 = df['x1']\n",
    "    x2 = df['x2']\n",
    "    x3 = df['x3']\n",
    "    y0 = df['y0']\n",
    "    y1 = df['y1']\n",
    "    y2 = df['y2']\n",
    "    y3 = df['y3']\n",
    "    \n",
    "    min_x = np.minimum(df['x0'], df['x3'])\n",
    "    min_y = np.minimum(df['y0'], df['y1'])\n",
    "    max_x = np.maximum(df['x1'], df['x2'])\n",
    "    max_y = np.maximum(df['y2'], df['y3'])\n",
    "    box_ratio = (max_x - min_x) / (max_y - min_y)\n",
    "    shear_y0 = -box_ratio * (y2 - y3) / (x2 - x3)\n",
    "    shear_y1 = -box_ratio * (y1 - y0) / (x1 - x0)\n",
    "    shear_x0 = -box_ratio * (x3 - x0) / (y3 - y0)\n",
    "    shear_x1 = -box_ratio * (x2 - x1) / (y2 - y1)\n",
    "    shear_y = (shear_y0 + shear_y1) / 2\n",
    "    shear_x = (shear_x0 + shear_x1) / 2\n",
    "    df['min_x'] = min_x\n",
    "    df['min_y'] = min_y\n",
    "    df['max_x'] = max_x\n",
    "    df['max_y'] = max_y\n",
    "    df['shear_x'] = shear_x\n",
    "    df['shear_y'] = shear_y\n",
    "\n",
    "    plate_chars = plate_characters\n",
    "    bbox = df[['min_x', 'min_y', 'max_x', 'max_y', 'type']].values\n",
    "    vertex = df[['x0', 'y0', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3','type']].values\n",
    "    cxy_col = [str(i) for i in range(18)]\n",
    "    char_cxy = df[cxy_col].values\n",
    "    plate_type = df['type'].values\n",
    "\n",
    "    text_len = max_sequence\n",
    "    m = len(df)\n",
    "    class_nums = np.zeros((m, text_len)) - 1\n",
    "    for i in range(m):\n",
    "        text0 = df.loc[i, 'text']\n",
    "        for j in range(len(text0)):\n",
    "            class_num = plate_chars.index(text0[j])\n",
    "            class_nums[i, j] = class_num\n",
    "    print('class_nums', class_nums.shape)\n",
    "    print('char_cxy', char_cxy.shape)\n",
    "    \n",
    "    label = np.concatenate((vertex, class_nums, char_cxy), axis=-1)    \n",
    "    print('label', label.shape)\n",
    "    \n",
    "    img_path_list = list(path_synthetic + df['path'].values)\n",
    "    return img_path_list, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paths, labels = read_synthetic(10000)\n",
    "print('labels', len(labels), len(paths))\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i_index = np.arange(10)\n",
    "np.random.shuffle(i_index)\n",
    "i_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "i_index = np.arange(len(paths))\n",
    "np.random.shuffle(i_index)\n",
    "for i in i_index:\n",
    "    path_img = paths[i]\n",
    "    label = labels[i]\n",
    "    if os.path.isfile(path_img):\n",
    "        img = Image.open(path_img)\n",
    "        arr = np.array(img)\n",
    "        \n",
    "        \n",
    "        img_h, img_w, img_c = arr.shape\n",
    "        #print('label', label.shape)\n",
    "        coord = label[:8]\n",
    "        type_text = label[8:8+1+max_sequence]        \n",
    "        char_cxy = label[8+1+max_sequence:]\n",
    "        \n",
    "        coord_2d = np.reshape(coord, [-1, 2])\n",
    "        coord_2d_norm = coord_2d / (np.array((img_w, img_h), np.float))\n",
    "        coord_norm = np.reshape(coord_2d_norm, [-1])\n",
    "        \n",
    "        char_cxy_2d = np.reshape(char_cxy, [-1, 2])\n",
    "        char_cxy_2d_norm = char_cxy_2d / (np.array((img_w, img_h), np.float))\n",
    "        char_cxy_norm = np.reshape(char_cxy_2d_norm, [-1])\n",
    "        \n",
    "        label_norm = np.concatenate((coord_norm, type_text, char_cxy_norm), -1)\n",
    "        \n",
    "        x_list.append(arr)\n",
    "        y_list.append(label_norm)\n",
    "        if len(x_list)%100 == 0 :\n",
    "            print(len(paths), len(x_list))\n",
    "        if len(x_list)>max_data_m:\n",
    "            break\n",
    "print('x_list', len(x_list), len(y_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_plate(\n",
    "    image, y, figsize=(12, 12), linewidth=1, color=[0, 0, 1]\n",
    "):\n",
    "    \"\"\"Visualize Detections\"\"\"    \n",
    "    img_h, img_w, img_c = image.shape\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    vertices_norm = y[:8]    \n",
    "    plate_type = y[8]\n",
    "    plate_text = y[9:]\n",
    "    vertices_norm_2d = np.reshape(vertices_norm, [-1, 2])\n",
    "    vertices_2d = vertices_norm_2d * np.array((img_w, img_h), np.float)\n",
    "    \n",
    "    x0, y0, x1, y1, x2, y2, x3, y3 = np.reshape(vertices_2d, [-1])\n",
    "    \n",
    "    w, h = x2 - x1, y2 - y1    \n",
    "    color = [1,0,0]\n",
    "    linewidth = 10\n",
    "    plt.plot(x0, y0, x1, y1, 'go-', linewidth=linewidth)\n",
    "    plt.plot(x1, y1, x2, y2, 'ro--', linewidth=linewidth)\n",
    "    plt.plot(x2, y2, x3, y3, marker = 'o', linewidth=linewidth)\n",
    "    plt.plot(x3, y3, x0, y0, marker = 'o', linewidth=linewidth)\n",
    "        \n",
    "    txt = str.format('(%d)' % (plate_type)) + str(plate_text)\n",
    "    ax.text(x0, y0, txt, bbox={\"facecolor\": [1,1,0], \"alpha\": 0.4}, clip_box=ax.clipbox, clip_on=True,)\n",
    "        \n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data(X, Y, stride=1):\n",
    "    for i in range(len(X)):\n",
    "        if i%stride==0:            \n",
    "            ax = visualize_plate(X[i], Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_data(x_list, y_list, stride=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_matrix(x, y):\n",
    "    z = x * 0\n",
    "    o = z + 1\n",
    "    mat = tf.stack([o, z, x, z, o, y], -1)\n",
    "    row = tf.stack([z, z, z+1], -1)\n",
    "    mat = tf.concat((mat, row), -1)\n",
    "    mat = tf.reshape(mat, [-1, 3, 3])\n",
    "    return mat\n",
    "\n",
    "def scale_matrix(x, y):\n",
    "    z = x * 0\n",
    "    mat = tf.stack([x, z, z, z, y, z], -1)\n",
    "    row = tf.stack([z, z, z + 1], -1)\n",
    "    mat = tf.concat((mat, row), -1)\n",
    "    mat = tf.reshape(mat, [-1, 3, 3])\n",
    "    return mat\n",
    "\n",
    "def rotate_matrix(radian):\n",
    "    c = tf.cos(radian)\n",
    "    s = tf.sin(radian)\n",
    "    z = c * 0\n",
    "    mat = tf.stack([c, -s, z, s, c, z], -1)\n",
    "    row = tf.stack([z, z, z + 1], -1)\n",
    "    mat = tf.concat((mat, row), -1)\n",
    "    mat = tf.reshape(mat, [-1, 3, 3])\n",
    "    return mat\n",
    "\n",
    "\n",
    "def shear_x_matrix(radian_x):\n",
    "    x = tan(radian_x)\n",
    "    z = x * 0\n",
    "    o = z + 1\n",
    "    mat = tf.stack([o, x, z, z, o, z], -1)\n",
    "    row = tf.stack([z, z, z + 1], -1)\n",
    "    mat = tf.concat((mat, row), -1)\n",
    "    mat = tf.reshape(mat, [-1, 3, 3])\n",
    "    return mat\n",
    "\n",
    "def shear_y_matrix(radian_y):\n",
    "    y = tan(radian_y)\n",
    "    z = y * 0\n",
    "    o = z + 1\n",
    "    mat = tf.stack([o, z, z, y, o, z], -1)\n",
    "    row = tf.stack([z, z, z + 1], -1)\n",
    "    mat = tf.concat((mat, row), -1)\n",
    "    mat = tf.reshape(mat, [-1, 3, 3])\n",
    "    return mat\n",
    "\n",
    "def shear_matrix(radian_x, radian_y):\n",
    "    \n",
    "    x = tan(radian_x)\n",
    "    y = tan(radian_y)\n",
    "    z = x * 0\n",
    "    o = z + 1\n",
    "    mat = tf.stack([o, x, z, y, o, z], -1)\n",
    "    row = tf.stack([z, z, z + 1], -1)\n",
    "    mat = tf.concat((mat, row), -1)\n",
    "    mat = tf.reshape(mat, [-1, 3, 3])\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_norm_to_uv(coord):\n",
    "    return coord * 2 - 1 \n",
    "\n",
    "def convert_uv_to_norm_to(coord):\n",
    "    return coord + 1 / 2\n",
    "\n",
    "\n",
    "def transform_uv(uv, mat):\n",
    "    #coord : (m, n, 2)\n",
    "    #theta : (m, 2, 3)    \n",
    "    inv_mat = tf.linalg.inv(mat)        \n",
    "    xyo = tf.concat((uv, 1 + 0 * uv[:, :, :1]), -1)\n",
    "    new_xy = tf.einsum('mrc,msc->mrs', inv_mat, xyo)\n",
    "    new_xy = tf.transpose(new_xy, [0, 2, 1])\n",
    "    new_xy = new_xy[:, :, :2]\n",
    "    return new_xy\n",
    "\n",
    "\n",
    "def transform_xy(xy, theta):\n",
    "    m = tf.shape(xy)[0]\n",
    "    theta = tf.linalg.inv(theta)\n",
    "    theta = theta[:, :2]\n",
    "    # xy [0, 1] > [-1, 1]\n",
    "    xy = (xy - 0.5) * 2\n",
    "    theta = tf.reshape(theta, [-1, 2, 3])\n",
    "    xy = tf.reshape(xy, [m, -1, 2])\n",
    "    xyo = tf.concat((xy, 1 + 0 * xy[:, :, :1]), -1)\n",
    "    new_xy = tf.einsum('mrc,msc->mrs', theta, xyo)\n",
    "    new_xy = tf.transpose(new_xy, [0, 2, 1])\n",
    "\n",
    "    return new_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = sign(x) = -1 if x < 0; 0 if x == 0; 1 if x > 0.\n",
    "def sign(v):\n",
    "    return tf.cast(v > 0, tf.float32) + -1 * tf.cast(v < 0, tf.float32)\n",
    "\n",
    "def tan(v):\n",
    "    return tf.sin(v)/tf.cos(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x1(t1, t2, width, height):\n",
    "    a = sign(t2) * width - height * tf.sin(t2)/tf.cos(t2)\n",
    "    b = (sign(t2) * tf.cos(t1) * tf.cos(t2) - sign(t1) * tf.sin(t1) * tf.sin(t2)) / (tf.cos(t1)*tf.cos(t2))\n",
    "    x1 = a / b\n",
    "    return x1\n",
    "\n",
    "def get_v1_v2(t1, t2, width, height):\n",
    "    x1 = get_x1(t1, t2, width, height)\n",
    "    #x1 = get_x1_new(t1, t2, width, height)\n",
    "    y1 = x1 / tf.cos(t1) * tf.sin(t1)\n",
    "    x2 = width * sign(t2) - sign(t2) * x1\n",
    "    y2 = height - sign(t1) * y1\n",
    "    return x1,y1,x2,y2\n",
    "\n",
    "def get_wH(t1, t2, width, height):\n",
    "    x1, y1, x2, y2 = get_v1_v2(t1, t2, width, height)\n",
    "    w = x1/tf.cos(t1)\n",
    "    h = y2/tf.cos(t2)\n",
    "    pi = 3.141592653589793\n",
    "    right = 90 * pi / 180\n",
    "    H = tf.sin(right - t1 - t2) * h\n",
    "    return w / width, H / height\n",
    "\n",
    "def get_align_scale_matrix(radian_x, radian_y, width, height):\n",
    "    min_angle = 0.0001\n",
    "    rotate_mat = rotate_matrix(-radian_y)\n",
    "    shear_x_mat = shear_x_matrix(-radian_x - radian_y)\n",
    "    \n",
    "    is_zero_radian_x = tf.cast(tf.abs(radian_x) < min_angle, tf.float32)\n",
    "    is_zero_radian_y = tf.cast(tf.abs(radian_y) < min_angle, tf.float32)\n",
    "    radian_x = is_zero_radian_x * sign(radian_x) * radian_x * 0+min_angle + (1-is_zero_radian_x) * radian_x\n",
    "    radian_y = is_zero_radian_y * sign(radian_y) * radian_y * 0+min_angle + (1-is_zero_radian_y) * radian_y\n",
    "    radian_x = tf.where(tf.abs(radian_x) < min_angle, sign(radian_x) * radian_x * 0+min_angle, radian_x)\n",
    "    radian_y = tf.where(tf.abs(radian_y) < min_angle, sign(radian_y) * radian_y * 0+min_angle, radian_y)\n",
    "    w, h = get_wH(-radian_y, -radian_x, width, height) \n",
    "    scale_down_rotate_o = scale_matrix(w, h)\n",
    "\n",
    "    rot_mat = tf.matmul(rotate_mat, shear_x_mat)\n",
    "    rot_scale_mat = tf.matmul(rot_mat, scale_down_rotate_o) #[2,3,3] vs [4,3,3]\n",
    "\n",
    "    return rot_scale_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.linspace(-1.0, 1.0, 6, name='linspace_x')\n",
    "y = tf.linspace(-1.0, 1.0, 3, name='linspace_y')\n",
    "x_t, y_t = tf.meshgrid(x, y, name='meshgrid')\n",
    "x_t, y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2 * (tf.range(6)/5 - 0.5)\n",
    "x = tf.reshape(x, [1, -1])\n",
    "x = tf.tile(x, [3, 1])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_grid_generator(height, width, theta):\n",
    "    num_batch = tf.shape(theta)[0]\n",
    "    \n",
    "    x = tf.linspace(-1.0, 1.0, width)\n",
    "    y = tf.linspace(-1.0, 1.0, height)\n",
    "    x_t, y_t = tf.meshgrid(x, y)\n",
    "    x_t_flat = tf.reshape(x_t, [-1])\n",
    "    y_t_flat = tf.reshape(y_t, [-1])\n",
    "\n",
    "    ones = tf.ones_like(x_t_flat)\n",
    "    sampling_grid = tf.stack([x_t_flat, y_t_flat, ones])  # (3, h*w)\n",
    "    sampling_grid = tf.expand_dims(sampling_grid, axis=0)\n",
    "    # sampling_grid = tf.tile(sampling_grid, tf.stack([num_batch, 1, 1]))#(num_batch, 3, h*w)\n",
    "    sampling_grid = tf.tile(sampling_grid, [num_batch, 1, 1])  # (num_batch, 3, h*w)\n",
    "    theta = tf.cast(theta, tf.float32)\n",
    "    sampling_grid = tf.cast(sampling_grid, tf.float32)\n",
    "\n",
    "    batch_grids = tf.matmul(theta, sampling_grid)  # (m, 2, 3)@(m, 3, h*w)=(m,2,h*w)\n",
    "    batch_grids = tf.reshape(batch_grids, [num_batch, 2, height, width])\n",
    "    return batch_grids\n",
    "\n",
    "\n",
    "def get_pixel_value(img, x, y):\n",
    "    # img (m,h,w,c)\n",
    "    # x,y (m,h,w)\n",
    "    shape = tf.shape(x)\n",
    "    m = shape[0]\n",
    "    h = shape[1]\n",
    "    w = shape[2]\n",
    "    batch_idx = tf.range(0, m)\n",
    "    batch_idx = tf.reshape(batch_idx, [m, 1, 1])\n",
    "    b = tf.tile(batch_idx, [1, h, w])\n",
    "\n",
    "    indices = tf.stack([b, y, x], axis=3)  # (m,h,w,3)\n",
    "\n",
    "    return tf.gather_nd(img, indices)\n",
    "\n",
    "\n",
    "def bilinear_sampler(img, batch_grids):\n",
    "    # batch_grids (m, 2, h, w)\n",
    "    # img (m,h,w,c)\n",
    "    uv_x = batch_grids[:, 0]\n",
    "    uv_y = batch_grids[:, 1]\n",
    "    H = tf.shape(img)[1]\n",
    "    W = tf.shape(img)[2]\n",
    "    max_y = tf.cast(H - 1, tf.float32)\n",
    "    max_x = tf.cast(W - 1, tf.float32)\n",
    "    # x [-1, 1]\n",
    "    x = 0.5 * ((uv_x + 1.0) * max_x)\n",
    "    y = 0.5 * ((uv_y + 1.0) * max_y)\n",
    "\n",
    "    # grab 4 nearest corner points for each (x_i, y_i)\n",
    "    x0 = tf.floor(x)  # precision bad?\n",
    "    x1 = x0 + 1\n",
    "    y0 = tf.floor(y)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # clip out of boundary index\n",
    "    x0 = tf.clip_by_value(x0, 0, max_x)\n",
    "    x1 = tf.clip_by_value(x1, 0, max_x)\n",
    "    y0 = tf.clip_by_value(y0, 0, max_y)\n",
    "    y1 = tf.clip_by_value(y1, 0, max_y)\n",
    "\n",
    "    # deltas\n",
    "    wa = (x1 - x) * (y1 - y)\n",
    "    wb = (x1 - x) * (y - y0)\n",
    "    wc = (x - x0) * (y1 - y)\n",
    "    wd = (x - x0) * (y - y0)\n",
    "\n",
    "    wa = tf.expand_dims(wa, -1)\n",
    "    wb = tf.expand_dims(wb, -1)\n",
    "    wc = tf.expand_dims(wc, -1)\n",
    "    wd = tf.expand_dims(wd, -1)\n",
    "\n",
    "    x0 = tf.cast(x0, tf.int32)\n",
    "    x1 = tf.cast(x1, tf.int32)\n",
    "    y0 = tf.cast(y0, tf.int32)\n",
    "    y1 = tf.cast(y1, tf.int32)\n",
    "\n",
    "    Ia = get_pixel_value(img, x0, y0)\n",
    "    Ib = get_pixel_value(img, x0, y1)\n",
    "    Ic = get_pixel_value(img, x1, y0)\n",
    "    Id = get_pixel_value(img, x1, y1)\n",
    "\n",
    "    out = tf.add_n([wa*Ia, wb*Ib, wc*Ic, wd*Id])\n",
    "    #out = wa * Ia + wb * Ib + wc * Ic + wd * Id\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def sampling(net, theta, dst_h, dst_w):\n",
    "    theta = tf.reshape(theta, [-1, 2, 3])\n",
    "    #h = tf.shape(net)[1]\n",
    "    #w = tf.shape(net)[2]\n",
    "    batch_grids = affine_grid_generator(dst_h, dst_w, theta)\n",
    "    out = bilinear_sampler(net, batch_grids)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_center_and_size(bbox):\n",
    "    x0, y0, x1, y1 = tf.split(bbox, 4, -1)\n",
    "    w = x1 - x0\n",
    "    h = y1 - y0\n",
    "    cx = (x1 + x0) / 2\n",
    "    cy = (y1 + y0) / 2\n",
    "    return cx, cy, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = tf.constant(x_list[:1])\n",
    "Y = tf.constant(y_list[:1])\n",
    "X = tf.cast(X, tf.float32)\n",
    "X.shape, Y.shape, Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta_from_coords(coords):\n",
    "    x0 = coords[:, 0, 0]\n",
    "    y0 = coords[:, 0, 1]\n",
    "    x1 = coords[:, 1, 0]\n",
    "    y1 = coords[:, 1, 1]\n",
    "    x2 = coords[:, 2, 0]\n",
    "    y2 = coords[:, 2, 1]\n",
    "    x3 = coords[:, 3, 0]\n",
    "    y3 = coords[:, 3, 1]\n",
    "        \n",
    "    tx = (x0 + x1 + x2 + x3)/4\n",
    "    ty = (y0 + y1 + y2 + y3)/4\n",
    "    #scale_x = ((x1 - x0) + (x2 - x3))/2    \n",
    "    #scale_y = ((y3 - y0) + (y2 - y1))/2\n",
    "    shear_x = -((x0 - x3) / (y0 - y3) + (x1 - x2) / (y1 - y2)) / 2\n",
    "    shear_y = -((y1 - y0) / (x1 - x0) + (y2 - y3) / (x2 - x3)) / 2\n",
    "    shear_x = tf.math.atan(shear_x)\n",
    "    shear_y = tf.math.atan(shear_y)\n",
    "    \n",
    "    x_min = tf.reduce_min(coords[:, :, 0], 1)\n",
    "    x_max = tf.reduce_max(coords[:, :, 0], 1)\n",
    "    y_min = tf.reduce_min(coords[:, :, 1], 1)\n",
    "    y_max = tf.reduce_max(coords[:, :, 1], 1)\n",
    "    w = x_max - x_min\n",
    "    h = y_max - y_min\n",
    "    scale_x = w/2\n",
    "    scale_y = h/2\n",
    "    \n",
    "    return tx, ty, scale_x, scale_y, shear_x, shear_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transform_matrix(tx, ty, sx, sy, shear_x, shear_y):    \n",
    "    shift_mat = shift_matrix(tx, ty)\n",
    "    scale_mat = scale_matrix(sx, sy)    \n",
    "    \n",
    "    w = sx * 2\n",
    "    h = sy * 2\n",
    "    align_scale_mat = get_align_scale_matrix(shear_x, shear_y, w, h)    \n",
    "    tm = tf.matmul(shift_mat, align_scale_mat)\n",
    "    tm = tf.matmul(tm, scale_mat)\n",
    "    tm = tf.cast(tm, tf.float32)\n",
    "    return tm\n",
    "\n",
    "def convert_transform_matrix(tx, ty, sx, sy, shear_x, shear_y):    \n",
    "    shift_mat = shift_matrix(tx, ty)\n",
    "    scale_mat = scale_matrix(sx, sy)    \n",
    "    shear_mat = shear_matrix(shear_x, shear_y)\n",
    "    \n",
    "    tm = tf.matmul(shift_mat, scale_mat)\n",
    "    tm = tf.matmul(tm, shear_mat)\n",
    "    tm = tf.cast(tm, tf.float32)\n",
    "    return tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_align_matrix(vertices_uv):\n",
    "    cx, cy, sx, sy, shear_x, shear_y = get_theta_from_coords(vertices_uv)        \n",
    "    transform_mat = generate_transform_matrix(cx, cy, sx, sy, shear_x, shear_y)\n",
    "    return transform_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augment_transform_matrix(m, delta):\n",
    "    z = tf.zeros(m)    \n",
    "    shear_y = tf.random.normal(tf.shape(z), stddev=delta)\n",
    "    shear_x = tf.random.normal(tf.shape(z), stddev=delta)\n",
    "    ty = tf.random.normal(tf.shape(z), stddev=delta)\n",
    "    tx = tf.random.normal(tf.shape(z), stddev=delta)\n",
    "\n",
    "    #width_scope = [0.07, 0.3]  # from [0.156, 0.116]\n",
    "    sx = tf.random.uniform(tf.shape(z), minval=1, maxval=1 + delta)\n",
    "    sy = tf.random.uniform(tf.shape(z), minval=1, maxval=1 + delta)\n",
    "    sx += tf.abs(tx)\n",
    "    sy += tf.abs(ty)\n",
    "\n",
    "    #thetas = tf.stack([tx, ty, sx, sy, shear_x, shear_y], 1)\n",
    "    return tx, ty, sx, sy, shear_x, shear_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aug_matrix(vertices_uv, delta):    \n",
    "    transform_mat = get_align_matrix(vertices_uv)\n",
    "    m = tf.shape(vertices_uv)[0]\n",
    "    \n",
    "    cx, cy, sx, sy, shear_x, shear_y = get_augment_transform_matrix(m, delta)    \n",
    "    transform_mat = convert_transform_matrix(cx, cy, sx, sy, shear_x, shear_y)\n",
    "    \n",
    "    return transform_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.cast(Y, tf.float32)\n",
    "vertices = Y[:, :8]\n",
    "plate_type = Y[:, 8]\n",
    "plate_text = Y[:, 9:9 + max_sequence]\n",
    "char_cxy = Y[:, 9 + max_sequence:9 + max_sequence + max_sequence*2]\n",
    "\n",
    "vertices = tf.reshape(vertices, [-1, 4, 2])\n",
    "char_cxy = tf.reshape(char_cxy, [-1, max_sequence, 2])\n",
    "vertices_uv = convert_norm_to_uv(vertices)\n",
    "char_cxy_uv = convert_norm_to_uv(char_cxy)\n",
    "align_mat = get_align_matrix(vertices_uv)\n",
    "aug_mat = get_aug_matrix(vertices_uv, delta=0.1)\n",
    "transform_mat = tf.matmul(align_mat, aug_mat)\n",
    "transform_mat.shape, transform_mat.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sampled = sampling(X, transform_mat[:, :2], 200, 400)\n",
    "x_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_vertices_uv = transform_uv(vertices_uv, transform_mat)\n",
    "transformed_char_cxy_uv = transform_uv(char_cxy_uv, transform_mat)\n",
    "transformed_vertices_uv.shape, transformed_char_cxy_uv.shape, transformed_vertices_uv[0], transformed_char_cxy_uv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cx, y_cy, y_sx, y_sy, y_shear_x, y_shear_y = get_theta_from_coords(transformed_vertices_uv)        \n",
    "tf.stack((y_cx, y_cy, y_sx, y_sy, y_shear_x, y_shear_y), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_char_cxy_uv = transform_uv(char_cxy_uv, transform_mat)\n",
    "transformed_char_cxy_uv.shape, transformed_char_cxy_uv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sampled_img = x_sampled.numpy().astype(np.uint8)\n",
    "x_sampled_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_sample_concat = np.concatenate((x_sampled_img), axis=1)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(x_sample_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aug_align_mat = generate_transform_matrix(y_cx, y_cy, y_sx, y_sy, y_shear_x, y_shear_y)\n",
    "x_aug_aligned_sampled = sampling(x_sampled, aug_align_mat[:, :2], 200, 400)\n",
    "x_aug_aligned_sampled.shape\n",
    "x_aug_aligned_sampled_img = x_aug_aligned_sampled.numpy().astype(np.uint8)\n",
    "x_sample_concat = np.concatenate((x_aug_aligned_sampled_img[:10]), axis=1)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(x_sample_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = visualize_plate(x_list[0], y_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalilze_4d(x):\n",
    "    mini = tf.reduce_min(x, [1, 2], True)\n",
    "    maxi = tf.reduce_max(x, [1, 2], True)\n",
    "    return (x - mini) / (maxi - mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, label):\n",
    "    \n",
    "    label = tf.expand_dims(label, 0)\n",
    "    X = tf.expand_dims(X, 0)\n",
    "    vertices = label[:, :8]\n",
    "    plate_type = label[:, 8]\n",
    "    plate_text = label[:, 9:9 + max_sequence]\n",
    "    char_cxy = label[:, 9 + max_sequence:9 + max_sequence + max_sequence*2]\n",
    "\n",
    "    vertices = tf.reshape(vertices, [-1, 4, 2])\n",
    "    char_cxy = tf.reshape(char_cxy, [-1, max_sequence, 2])\n",
    "    vertices_uv = convert_norm_to_uv(vertices)\n",
    "    char_cxy_uv = convert_norm_to_uv(char_cxy)\n",
    "    align_mat = get_align_matrix(vertices_uv)\n",
    "    aug_mat = get_aug_matrix(vertices_uv, delta=0.01)#hyper\n",
    "    transform_mat = tf.matmul(align_mat, aug_mat)\n",
    "    \n",
    "    X = tf.cast(X, tf.float32)\n",
    "    x_sampled = sampling(X, transform_mat[:, :2], padded_image_shape[0], padded_image_shape[1])\n",
    "    transformed_vertices_uv = transform_uv(vertices_uv, transform_mat)\n",
    "    transformed_char_cxy_uv = transform_uv(char_cxy_uv, transform_mat)\n",
    "    #image = tf.image.resize(image, padded_image_shape)    \n",
    "    y_cx, y_cy, y_sx, y_sy, y_shear_x, y_shear_y = get_theta_from_coords(transformed_vertices_uv)\n",
    "    y_align = tf.stack((y_cx, y_cy, y_sx, y_sy, y_shear_x, y_shear_y), -1)\n",
    "    \n",
    "    return x_sampled, y_align, plate_text, transformed_char_cxy_uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass    \n",
    "    \n",
    "    def _encode_sample(self, image_shape, y_align, gt_text, gt_cxy_uv):\n",
    "        \n",
    "        y_align = tf.reshape(y_align, [-1])\n",
    "        gt_text = tf.reshape(gt_text, [-1])\n",
    "        gt_cxy_uv_flat = tf.reshape(gt_cxy_uv, [-1])\n",
    "        label = tf.concat([y_align, gt_text, gt_cxy_uv_flat], axis=-1)        \n",
    "        return label\n",
    "    \n",
    "    def encode_batch(self, batch_images, y_align, gt_text, gt_cxy_uv):\n",
    "        \n",
    "        images_shape = tf.shape(batch_images)\n",
    "        batch_size = images_shape[0]        \n",
    "                            \n",
    "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
    "        for i in range(batch_size):\n",
    "            label = self._encode_sample(images_shape, y_align[i], gt_text[i], gt_cxy_uv[i])\n",
    "            labels = labels.write(i, label)\n",
    "        \n",
    "        batch_images = tf.cast(batch_images, tf.float32)\n",
    "        label = labels.stack()\n",
    "        return batch_images, label      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, MaxPool2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulizer = tf.keras.regularizers.L2(l1)\n",
    "\n",
    "def residual_block(x: Tensor, downsample: bool, filters: int, kernel_size: int = 3) -> Tensor:\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides= (1 if not downsample else 2),\n",
    "               filters=filters, \n",
    "               activation=activation,\n",
    "               padding=\"same\",\n",
    "               kernel_initializer=kernel_init,\n",
    "               kernel_regularizer=regulizer)(x)    \n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\",\n",
    "               kernel_initializer=kernel_init,\n",
    "               kernel_regularizer=regulizer)(y)   \n",
    "    \n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=3,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   activation=activation,\n",
    "                   padding=\"same\",\n",
    "                   kernel_regularizer=regulizer)(x)\n",
    "    out = Add()([x, y])\n",
    "    out = ReLU()(out)\n",
    "    return out\n",
    "\n",
    "def create_resnet_backbone(inputs):\n",
    "    \n",
    "    #inputs = Input(shape=(None, None, 3))    \n",
    "    num_filters = 64\n",
    "    \n",
    "    #t = BatchNormalization()(inputs)    \n",
    "    t = Conv2D(kernel_size=7,\n",
    "               strides=2,\n",
    "               filters=num_filters,\n",
    "               activation=activation,\n",
    "               padding=\"same\",\n",
    "               kernel_initializer=kernel_init,\n",
    "               kernel_regularizer=regulizer, \n",
    "               )(inputs)\n",
    "    t = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(t)\n",
    "    \n",
    "    num_blocks_list = [2, 2, 2]#resnet-18\n",
    "    t_list = []\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        if i>=1:\n",
    "            t_list.append(t)\n",
    "        num_filters *= 2\n",
    "    \n",
    "        \n",
    "    return t\n",
    "\n",
    "\n",
    "def create_align_net(inputs):\n",
    "    \n",
    "    #inputs = Input(shape=(None, None, 3))    \n",
    "    num_filters = 64\n",
    "    \n",
    "    #t = BatchNormalization()(inputs)    \n",
    "    t = Conv2D(kernel_size=7,\n",
    "               strides=2,\n",
    "               filters=num_filters,\n",
    "               activation=activation,\n",
    "               padding=\"same\",\n",
    "               kernel_initializer=kernel_init,\n",
    "               kernel_regularizer=regulizer, \n",
    "               )(inputs)\n",
    "    t = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(t)\n",
    "    \n",
    "    num_blocks_list = [2, 2, 2, 2]#resnet-18\n",
    "    t_list = []\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        if i>=1:\n",
    "            t_list.append(t)\n",
    "        num_filters *= 2\n",
    "    \n",
    "    t = Flatten()(t)\n",
    "    t = Dense(256, activation=activation, kernel_regularizer=regulizer)(t)\n",
    "    t = Dense(6, name='align')(t)\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_encoding(max_sequence, seq, dimension_model):\n",
    "\n",
    "    if max_sequence % 2 == 1:\n",
    "        max_sequence += 1\n",
    "\n",
    "    pos = tf.range(max_sequence, dtype=tf.float32)\n",
    "    pos = tf.reshape(pos, [max_sequence, 1])\n",
    "    theta = pos/tf.pow(10000.0, tf.range(dimension_model, dtype=tf.float32)/dimension_model)\n",
    "    emb_even = tf.sin(theta)[:, ::2]\n",
    "    emb_odd = tf.cos(theta)[:, 1::2]\n",
    "    emb_even_odd = tf.stack((emb_even, emb_odd), axis=-1)\n",
    "    emb_even_odd = tf.reshape(emb_even_odd, [max_sequence, dimension_model])\n",
    "    emb = tf.expand_dims(emb_even_odd[:seq], 0)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_multi_head_attention(layers, y, num_units, s, head=head_n):\n",
    "    '''\n",
    "    :param y: (m, s, c) > padding >(m, S, c)\n",
    "    :param x: == y\n",
    "    :param num_units: 256\n",
    "    :param head: 4\n",
    "    :return: (m, s, c)\n",
    "    '''\n",
    "\n",
    "    z_expand = tf.expand_dims(y, axis=1)\n",
    "    one = tf.ones_like(z_expand[:1, :, :, 0], dtype=tf.float32)\n",
    "    one = tf.tile(one, [1, s, 1])\n",
    "    #triangle_mask = tf.linalg.LinearOperatorLowerTriangular(one).to_dense()#disable on .pb?    \n",
    "    hot = tf.one_hot(tf.range(s, dtype=tf.int64), s)#(s, s)\n",
    "    acumulate_hot = []\n",
    "    for i in range(s):\n",
    "        row = hot[i]\n",
    "        for j in range(i):\n",
    "            row += hot[j]\n",
    "        \n",
    "        acumulate_hot.append(row)\n",
    "    \n",
    "    triangle_mask = tf.stack(acumulate_hot, axis=0)\n",
    "    triangle_mask = tf.cast(triangle_mask, tf.float32)            \n",
    "        \n",
    "    QKV = layers[0](z_expand)\n",
    "    #QKV = slim.fully_connected(z_expand, 3 * num_units, activation_fn=None, scope='fc_query_key_value')\n",
    "    QKV = tf.tile(QKV, [1, s, 1, 1])\n",
    "    QKV = tf.reshape(QKV, [-1, s, 3 * num_units])\n",
    "\n",
    "    query, key, value = tf.split(QKV, 3, -1, name='masked_split')\n",
    "\n",
    "    Q = tf.concat(tf.split(query, head, axis=-1), 0)\n",
    "    K = tf.concat(tf.split(key, head, axis=-1), 0)\n",
    "    V = tf.concat(tf.split(value, head, axis=-1), 0)\n",
    "\n",
    "    relevant_score = tf.matmul(Q, tf.transpose(K, [0, 2, 1])) / np.sqrt(num_units)  # (m, q_s, c) * (m, c, k_s) = (m, q_s, k_s)\n",
    "    \n",
    "    relevant_score = tf.cast(relevant_score, tf.float32)\n",
    "    triangle_mask = tf.cast(triangle_mask, tf.float32)\n",
    "    relevant_score += -10000.0 * (1.0 - triangle_mask)        \n",
    "    \n",
    "    attention = tf.nn.softmax(relevant_score, axis=-1)\n",
    "    context = tf.matmul(attention, V)\n",
    "\n",
    "    attention_list = tf.split(attention, head, axis=0)\n",
    "    context_list = tf.split(context, head, axis=0)\n",
    "\n",
    "    attention = tf.reduce_mean(attention_list, axis=0)\n",
    "\n",
    "    context = tf.concat(context_list, axis=-1)\n",
    "    context_4d = tf.reshape(context, [-1, s, s, num_units])\n",
    "    eye = tf.eye(s, s)\n",
    "    eye = tf.reshape(eye, [1, s, s, 1])\n",
    "    context = tf.reduce_sum(eye * context_4d, axis=2)\n",
    "    \n",
    "    if True:\n",
    "        eye_sum = tf.reduce_sum(eye, axis=1)\n",
    "        context = context_4d[:, -1]\n",
    "\n",
    "    #context = slim.fully_connected(context, num_units, activation_fn=None, scope='Linear')    \n",
    "    context = layers[1](context)\n",
    "    return context, attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dot_product_2d(query, key, value, s, h, w, num_units):\n",
    "    print(s, 'Q', query.shape, 'K', key.shape, 'V', value.shape)\n",
    "    #Q (None, 1, 32) K (None, 4, 12, 32) V (None, 4, 12, 32)\n",
    "    #m = tf.shape(query)[0]    \n",
    "    hw = h * w\n",
    "    c = num_units\n",
    "    #relevant_score = tf.einsum('msc,mhwc->mhws', query, key) / np.sqrt(num_units)\n",
    "    query = tf.reshape(query, [-1, s, c])\n",
    "    query_trans = tf.transpose(query, [0, 2, 1])\n",
    "    key = tf.reshape(key, [-1, hw, c])\n",
    "    relevant_score = tf.matmul(key, query_trans) / np.sqrt(num_units)\n",
    "    \n",
    "    relevant_score_flat = tf.reshape(relevant_score, [-1, hw, s])#err\n",
    "    alignment_weights = tf.nn.softmax(relevant_score_flat, axis=1)\n",
    "\n",
    "    #alignment_prob = tf.reshape(alignment_weights, tf.shape(relevant_score))\n",
    "    alignment_prob = tf.reshape(alignment_weights, (-1, hw, s))\n",
    "    value = tf.reshape(value, (-1, hw, c))\n",
    "\n",
    "    #context = tf.einsum('mhws,mhwc->msc', alignment_prob, value)\n",
    "    alignment_prob = tf.transpose(alignment_prob, [0, 2, 1])#(mhws) > (m, s, hw)\n",
    "    #value = tf.transpose(value, [0, 2, 1])#(m,hw,c) > (m, c, hw)\n",
    "    context = tf.matmul(alignment_prob, value, name='context_matmul')\n",
    "\n",
    "    return context, alignment_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention_qkv(layers, y, x, h, w, num_units, s, head=head_n):\n",
    "    num_head_unit = num_units // head\n",
    "    #query = slim.fully_connected(y, num_units, activation_fn=None, scope='query')\n",
    "        \n",
    "    #key_value = slim.conv2d(x, num_units * 2, kernel_size=[3, 3], scope='key_value')\n",
    "    \n",
    "    key = layers[0](x)\n",
    "    value = layers[1](x)\n",
    "    #key_value = slim.fully_connected(x, num_units * 2, activation_fn=None, scope='key_value')\n",
    "    #key, value = tf.split(key_value, 2, -1)\n",
    "    query = y\n",
    "    Q = tf.concat(tf.split(query, head, axis=-1), 0)\n",
    "    K = tf.concat(tf.split(key, head, axis=-1), 0)\n",
    "    V = tf.concat(tf.split(value, head, axis=-1), 0)\n",
    "\n",
    "    context, attention = scale_dot_product_2d(Q, K, V, s, h, w, num_head_unit)  # (m * head, s, c)\n",
    "\n",
    "    attention_head = tf.split(attention, head, axis=0)\n",
    "    attention_head = tf.stack(attention_head, axis=0)\n",
    "    attention = tf.reduce_mean(attention_head, axis=0)\n",
    "    attention = tf.reshape(attention, [-1, s, h, w])\n",
    "    \n",
    "    context_list = tf.split(context, head, axis=0)\n",
    "    context = tf.concat(context_list, axis=-1)\n",
    "    #context = tf.cond(tf.logical_and(env.is_ensemble_multi_head, is_train), lambda: dropout_sub_head(context_list, head), lambda: tf.concat(context_list, axis=-1))\n",
    "    #context = slim.fully_connected(context, num_units, activation_fn=None, scope='linear')\n",
    "\n",
    "    return context, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_layer(layers, z, nets, h, w, s, num_units):\n",
    "    #z (m, S, num_units)\n",
    "    #x (m, h, w, ch)\n",
    "\n",
    "    sub_z, attention_weight = masked_multi_head_attention(layers[:2], z, num_units, s)\n",
    "    #z = layer_normalize(z + slim.dropout(sub_z, keep_prob=env.drop_prob_transformer, is_training=is_train))\n",
    "\n",
    "    sub_z, attention = multi_head_attention_qkv(layers[2:], z, nets, h, w, num_units, s)\n",
    "    #z = layer_normalize(z + slim.dropout(sub_z, keep_prob=env.drop_prob_transformer, is_training=is_train))\n",
    "\n",
    "    #sub_z = position_wise_feed_forward(z, num_units)\n",
    "    #z = layer_normalize(z + slim.dropout(sub_z, keep_prob=env.drop_prob_transformer, is_training=is_train))\n",
    "    \n",
    "    return sub_z, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_net_to_score(net, embedding_w):\n",
    "    embedding_w_trans = tf.transpose(embedding_w)\n",
    "    score = tf.einsum('nsc,cv->nsv', net, embedding_w_trans)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeNet(net, num_units, h, w):    \n",
    "    #embedding = keras.layers.Embedding(input_dim=num_classes, output_dim=num_units, name='embedding')    \n",
    "    embedding = Dense(num_units, use_bias=False, name='dense_embedding')\n",
    "    y_symbol = tf.zeros_like(net[:, 0, 0, :1], dtype=tf.int32) + SOS\n",
    "    \n",
    "    dense_0 = Dense(3 * num_units, name='masked_Dense_0')\n",
    "    dense_1 = Dense(num_units, name='masked_Dense_1')\n",
    "    dense_2 = Dense(num_classes, name='dense_to_score')\n",
    "    conv_0 = Conv2D(num_units, 3, padding='same', name='key')\n",
    "    conv_1 = Conv2D(num_units, 3, padding='same', name='value')\n",
    "    layers = [dense_0, dense_1, conv_0, conv_1]\n",
    "    values = []\n",
    "    y_symbol_hot = tf.one_hot(y_symbol, num_classes)\n",
    "    for i in range(max_sequence):\n",
    "        #z = tf.einsum('msv,vc->msc', y_symbol, embedding_w)\n",
    "        \n",
    "        z = embedding(y_symbol_hot)\n",
    "        #print('embedding_in', i, y_symbol)#(None, 1, 118)\n",
    "        #print('embedding_out', i, z)#(None, 1, 256)\n",
    "        \n",
    "        z = z * (num_units ** 0.5) + position_encoding(max_sequence + 1, i + 1, num_units)\n",
    "        #z = slim.dropout(z, keep_prob=env.drop_prob_transformer, is_training=is_train)\n",
    "                \n",
    "        z, attention = attention_layer(layers, z, net, h, w, i+1, num_units)\n",
    "        print('attention',i, attention)\n",
    "        #value = convert_net_to_score(z, embedding_w)\n",
    "        value = dense_2(z)\n",
    "        last_value = value[:, -1:]\n",
    "        values.append(last_value)\n",
    "        \n",
    "        y_symbol_hot = tf.concat((y_symbol_hot, tf.nn.softmax(last_value)), axis=1)#decode\n",
    "        #last_cls = tf.argmax(last_value, -1)\n",
    "        #last_cls = tf.cast(last_cls, tf.int32)\n",
    "        #y_symbol = tf.concat((y_symbol, last_cls), axis=1)    \n",
    "    \n",
    "    value_stack = tf.stack(values, axis=-2)\n",
    "    return value, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_map_uv(h, w):\n",
    "    #return (6, 18, 256)\n",
    "    x = tf.range(0.5, w, 1) / tf.cast(w, tf.float32) * 2.0 -1\n",
    "    y = tf.range(0.5, h, 1) / tf.cast(h, tf.float32) * 2.0 -1\n",
    "    X, Y = tf.meshgrid(x, y)\n",
    "    xy = tf.stack((X, Y), -1)\n",
    "    xy = tf.expand_dims(xy, axis=0)   \n",
    "    return xy\n",
    " \n",
    "\n",
    "def convert_attention_to_coord(attention, h, w, attention_threshold=0.0):\n",
    "    if attention_threshold > 0:\n",
    "        attention = attention * tf.cast(attention > attention_threshold, tf.float32)\n",
    "        attention = attention / tf.reduce_sum(attention, [1,2], keepdims=True)\n",
    "    attention_exp = tf.expand_dims(attention, -1)\n",
    "    coord_map = coordinate_map_uv(h, w)\n",
    "    \n",
    "    #before [?,9,4,12,1] * [1,4,12,1,2]. \n",
    "    #now    [?,9,4,12,1] * [1,1,4,12,2] > [?, 9, 4, 12, 2]\n",
    "    attention_coord = attention_exp * tf.expand_dims(coord_map, 1)  # (?, 6, 18, 6, 2)\n",
    "    char_coord = tf.reduce_sum(attention_coord, [2, 3])  # (?, 6, 2)\n",
    "    return char_coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_image_shape, np.array(padded_image_shape)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(num_classes):\n",
    "        \n",
    "    inputs = Input(shape=(padded_image_shape[0], padded_image_shape[1], 3))        \n",
    "    inputs_f = normalilze_4d(inputs)\n",
    "            \n",
    "    resnet_stride = 16\n",
    "    net_h = 6 \n",
    "    net_w = net_h * 3\n",
    "    image_h = net_h * resnet_stride\n",
    "    image_w = net_w * resnet_stride\n",
    "    \n",
    "    h_align = create_align_net(inputs_f)    \n",
    "    \n",
    "    if True:\n",
    "        cx, cy, sx, sy, shear_x, shear_y = tf.squeeze(tf.split(h_align, 6, -1), -1)\n",
    "        aug_align_mat = generate_transform_matrix(cx, cy, sx, sy, shear_x, shear_y)\n",
    "        inputs_aligned = sampling(inputs_f, aug_align_mat[:, :2], image_h, image_w)\n",
    "            \n",
    "    inputs_recog = tf.image.resize(inputs_f, (image_h, image_w)) + inputs_aligned*0.001 \n",
    "    net = create_resnet_backbone(inputs_recog)\n",
    "    print('resnet_out', net.shape)#(None, 4, 12, 512)\n",
    "    print('net_h,net_w',net_h,net_w)\n",
    "        \n",
    "    scores, attention = decodeNet(net, 256, net_h, net_w)\n",
    "    print('decodeNet_out', net)\n",
    "    print('decodeNet_out', attention)\n",
    "    \n",
    "    char_cxy_uv = convert_attention_to_coord(attention, net_h, net_w, 0.001)\n",
    "    print('h_char_cxy_uv', char_cxy_uv)\n",
    "    char_cxy_uv = tf.reshape(char_cxy_uv, [-1, max_sequence, 2])\n",
    "    scores = tf.reshape(scores, [-1, max_sequence, num_classes])\n",
    "    \n",
    "    output_decoder = tf.concat((char_cxy_uv, scores), -1)        \n",
    "    output_decoder_flat = tf.reshape(output_decoder, [-1, max_sequence * (2 + num_classes)])\n",
    "    output = tf.concat((h_align, output_decoder_flat), -1)\n",
    "    print('final_output', output)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=output)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignLoss(tf.losses.Loss):\n",
    "    \"\"\"Wrapper to combine both the losses\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlignLoss, self).__init__(reduction=\"auto\", name=\"AlignLoss\")        \n",
    "        pass\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        loss = tf.reduce_sum(tf.square(y_true - y_pred), -1)\n",
    "        return loss\n",
    "\n",
    "class DecodeLoss(tf.losses.Loss):\n",
    "    \"\"\"Wrapper to combine both the losses\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(DecodeLoss, self).__init__(reduction=\"auto\", name=\"DecodeLoss\")        \n",
    "        self._num_classes = num_classes\n",
    "        self._gamma = 2\n",
    "\n",
    "    def call(self, y_decoder, h_decoder):\n",
    "        h_decoder = tf.reshape(h_decoder, [-1, max_sequence, 2 + self._num_classes])\n",
    "        \n",
    "        y_text = tf.cast(y_decoder[:, :max_sequence], tf.int64)\n",
    "        y_char_cxy = y_decoder[:, max_sequence:]\n",
    "        y_char_cxy = tf.reshape(y_char_cxy, [-1, max_sequence, 2])\n",
    "        \n",
    "        h_char_cxy = h_decoder[:, :, :2]\n",
    "        h_text_score = h_decoder[:, :, 2:]\n",
    "        h_text = tf.argmax(h_text_score, -1)        \n",
    "        \n",
    "        valid_mask_f = tf.cast(y_text > -1, tf.float32)\n",
    "        valid_mask_i = tf.cast(y_text > -1, tf.int64)\n",
    "        \n",
    "        text_correct = tf.cast(tf.equal(y_text, h_text), tf.int64) * valid_mask_i * tf.range(max_sequence, dtype=tf.int64)#(m, seq)\n",
    "        text_correct_hot = tf.one_hot(text_correct, max_sequence)#(m,seq,seq)\n",
    "        text_correct_hot_axis_1 = tf.reduce_sum(text_correct_hot, axis=1)\n",
    "        loss_text_mask = tf.concat((tf.ones_like(text_correct_hot_axis_1[:, :1]), text_correct_hot_axis_1[:, :-1]), -1)\n",
    "        loss_text_mask = tf.cast(loss_text_mask, tf.float32)\n",
    "        \n",
    "        weight_char = tf.range(max_sequence, dtype=tf.float32)[::-1]\n",
    "        weight_char = tf.reshape(weight_char, [1, -1]) / (max_sequence/2)\n",
    "        \n",
    "        y_hot = tf.one_hot(y_text, self._num_classes)\n",
    "        cls_pt = tf.nn.softmax(h_text_score)        \n",
    "        cls_pt = tf.clip_by_value(cls_pt, 1e-7, 1.0 - 1e-7)\n",
    "        loss_cls_p = - tf.pow(1.0 - cls_pt, self._gamma) * y_hot * tf.math.log(cls_pt)\n",
    "        loss_cls_f = - tf.pow(cls_pt, self._gamma) * (1 - y_hot) * tf.math.log(1 - cls_pt)\n",
    "        \n",
    "        loss_cls = loss_text_mask * tf.reduce_sum(loss_cls_p + loss_cls_f, axis=-1)\n",
    "        loss_cxy = tf.reduce_sum(tf.abs(y_char_cxy - h_char_cxy), -1)\n",
    "        \n",
    "        loss = tf.boolean_mask(loss_cxy + loss_cls, y_text > -1)\n",
    "        #loss = valid_mask_f * (loss_cxy + 0.1 * loss_cls)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class NetLoss(tf.losses.Loss):\n",
    "    \"\"\"Wrapper to combine both the losses\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(NetLoss, self).__init__(reduction=\"auto\", name=\"NetLoss\")        \n",
    "        self._alignLoss = AlignLoss()\n",
    "        self._decodeLoss = DecodeLoss(num_classes)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_align = y_true[:, :6]\n",
    "        y_decoder = y_true[:, 6:]\n",
    "        \n",
    "        h_align = y_pred[:, :6]\n",
    "        h_decoder = y_pred[:, 6:]\n",
    "        \n",
    "        loss_align = self._alignLoss(y_align, h_align)\n",
    "        loss_decode = self._decodeLoss(y_decoder, h_decoder)        \n",
    "        loss = loss_align + loss_decode\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(y_true, y_pred):\n",
    "    y_align = y_true[:, :6]\n",
    "    y_decoder = y_true[:, 6:]\n",
    "\n",
    "    h_align = y_pred[:, :6]\n",
    "    h_decoder = y_pred[:, 6:]\n",
    "    \n",
    "    return tf.reduce_mean(tf.abs(y_align - h_align))\n",
    "\n",
    "def _acc(y_true, y_pred):    \n",
    "    y_text = tf.cast(y_true[:, :max_sequence], tf.int64)\n",
    "    y_char_cxy = y_true[:, max_sequence:]\n",
    "    y_char_cxy = tf.reshape(y_char_cxy, [-1, max_sequence, 2])\n",
    "\n",
    "    h_char_cxy = y_pred[:, :, :2]\n",
    "    h_text_score = y_pred[:, :, 2:]\n",
    "    h_text = tf.argmax(h_text_score, -1)\n",
    "\n",
    "    valid_mask = y_text > -1    \n",
    "    \n",
    "    acc = tf.boolean_mask(tf.equal(y_text, h_text), valid_mask)    \n",
    "    return acc\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_align = y_true[:, :6]\n",
    "    y_decoder = y_true[:, 6:]\n",
    "\n",
    "    h_align = y_pred[:, :6]\n",
    "    h_decoder = y_pred[:, 6:]\n",
    "    \n",
    "    h_decoder = tf.reshape(h_decoder, [-1, max_sequence, 2 + num_classes])      \n",
    "    return _acc(y_decoder, h_decoder)\n",
    "\n",
    "\n",
    "def dist_vertex(y_true, y_pred):\n",
    "    y_align = y_true[:, :6]\n",
    "    y_decoder = y_true[:, 6:]\n",
    "\n",
    "    h_align = y_pred[:, :6]\n",
    "    h_decoder = y_pred[:, 6:]\n",
    "    \n",
    "    y_text = tf.cast(y_decoder[:, :max_sequence], tf.int64)\n",
    "    y_char_cxy = y_decoder[:, max_sequence:]\n",
    "    y_char_cxy = tf.reshape(y_char_cxy, [-1, max_sequence, 2])\n",
    "    \n",
    "    h_decoder = tf.reshape(h_decoder, [-1, max_sequence, 2 + num_classes])        \n",
    "    h_cxy = h_decoder[:,:,:2]\n",
    "    \n",
    "    valid_mask = y_text > -1    \n",
    "    dist = tf.reduce_mean(tf.abs(y_char_cxy - h_cxy), -1)\n",
    "    return tf.boolean_mask(dist, valid_mask)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weight():   \n",
    "    weights_dir = path_weight\n",
    "    #latest_checkpoint = tf.train.latest_checkpoint(weights_dir)\n",
    "    latest_checkpoint = weights_dir \n",
    "    print('latest_checkpoint', latest_checkpoint)\n",
    "    model.load_weights(weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_list_train = x_list\n",
    "bbox_list_train = y_list\n",
    "len(input_list_train), len(bbox_list_train), type(input_list_train),input_list_train[0].shape, bbox_list_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    m = len(input_list_train)\n",
    "    \n",
    "    for i in range(m):\n",
    "        x = input_list_train[i]\n",
    "        y_box = bbox_list_train[i]        \n",
    "        yield (x, y_box)\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator, \n",
    "    output_types=(tf.uint8, tf.float32), \n",
    "    output_shapes=(tf.TensorShape([None, None, 3]), tf.TensorShape([36])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = tf.data.Dataset.from_tensor_slices((input_list_train, bbox_list_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "print(dataset)\n",
    "for example in tfds.as_numpy(dataset):\n",
    "    print('example', len(example))\n",
    "    image = example[0]\n",
    "    bbox = example[1]    \n",
    "    print(image.dtype, bbox.dtype, image.shape, bbox.shape, bbox)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "#dataset = dataset.batch(batch_size)\n",
    "train_dataset = dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
    "#train_dataset = train_dataset.batch(batch_size)\n",
    "#train_dataset = train_dataset.padded_batch(batch_size=batch_size)\n",
    "#train_dataset = train_dataset.padded_batch(batch_size=batch_size, padding_values=(0.0, 1e-8, -1), drop_remainder=True)\n",
    "train_dataset = train_dataset.map(label_encoder.encode_batch, num_parallel_calls=autotune)\n",
    "train_dataset = train_dataset.apply(tf.data.experimental.ignore_errors())\n",
    "train_dataset = train_dataset.prefetch(autotune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_dataset:\n",
    "    print(y.shape)\n",
    "    y = y[0]\n",
    "    y_align = y[:6]\n",
    "    y_recog = y[6:]\n",
    "    y_recog_text = y_recog[:max_sequence]\n",
    "    y_recog_cxy = y_recog[max_sequence:]\n",
    "    print(y_align)\n",
    "    print('y_recog_text', y_recog_text)\n",
    "    print('y_recog_cxy', tf.reshape(y_recog_cxy, [-1, 2]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#optimizer = tf.optimizers.SGD(learning_rate=1e-5, clipvalue=10.)#warm up clipvalue=10. !\n",
    "optimizer = tf.optimizers.SGD(learning_rate=1e-1, clipvalue=10.)#, clipvalue=10.\n",
    "loss_fn = NetLoss(num_classes)\n",
    "\n",
    "model = createModel(num_classes)\n",
    "model.compile(loss=loss_fn , optimizer=optimizer, metrics=[distance, dist_vertex,accuracy])#[distance, accuracy]\n",
    "\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=path_weight,\n",
    "        monitor=\"loss\",\n",
    "        save_best_only=False,\n",
    "        save_weights_only=True,\n",
    "        verbose=0,\n",
    "        save_freq=500\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(path_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "hist = model.fit(\n",
    "    train_dataset.take(10000),\n",
    "    validation_data=None,#val_dataset.take(2)\n",
    "    epochs=epochs, \n",
    "    callbacks=callbacks_list,#callbacks_list\n",
    "    verbose=1,\n",
    ")# b1:64ms, b2:62ms, b5:62ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(path_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_dataset: \n",
    "    \n",
    "    y_decode = label[:, 6:]\n",
    "    y_cls = tf.cast(y_decode[:, :max_sequence], tf.int64)\n",
    "    y_cxy = tf.reshape(y_decode[:, max_sequence:],[-1,max_sequence,2])\n",
    "    output = model.predict(image)\n",
    "    #print('output', output.shape)\n",
    "    output_decode = tf.reshape(output[:, 6:], [-1, max_sequence, 2 + num_classes])\n",
    "    cxy = output_decode[:, :, :2]\n",
    "    cls_score = output_decode[:, :, 2:]\n",
    "    #h_text_score = y_pred[:, :, 2:]\n",
    "    #h_text = tf.argmax(h_text_score, -1)\n",
    "    print('cls_score', cls_score.shape)\n",
    "    cls = tf.argmax(cls_score, -1)    \n",
    "    print('y', y_cls)\n",
    "    print('h', cls)\n",
    "    #print('y_cxy', y_cxy)\n",
    "    #print('cxy',cxy)\n",
    "    print('')\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(x_sample_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TF Lite model.\n",
    "with tf.io.gfile.GFile('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "!ls *.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sample = input_list_train[0]\n",
    "input_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(input_sample[52:-52,255:-255])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_resized = img.resize((padded_image_shape[1],padded_image_shape[0]))\n",
    "img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sample = np.expand_dims(np.array(img_resized), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes, num_classes * max_sequence, (2+num_classes) * max_sequence, 6+ (2+num_classes) * max_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print('input_details', input_details)\n",
    "print('output_details', output_details)\n",
    "\n",
    "# Test the TensorFlow Lite model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(input_sample, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
    "tflite_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_align = tflite_results[0, :6]\n",
    "out_recog = tflite_results[0, 6:]\n",
    "out_recog = np.reshape(out_recog, [2+num_classes, max_sequence])\n",
    "out_recog_cx = out_recog[:2]\n",
    "out_recog_text = out_recog[2:]\n",
    "cls_arg_max = np.argmax(out_recog_text, 0)\n",
    "tflite_results.shape, cls_arg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in model.trainable_variables:\n",
    "    print(var.name, var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
